{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with parquet files\n",
    "\n",
    "## Objective\n",
    "\n",
    "+ In this assignment, we will use the data downloaded with the module `data_manager` to create features.\n",
    "\n",
    "(11 pts total)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "+ This notebook assumes that price data is available to you in the environment variable `PRICE_DATA`. If you have not done so, then execute the notebook `01_materials/labs/2_data_engineering.ipynb` to create this data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variables using dotenv. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code below.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variable `PRICE_DATA`.\n",
    "+ Use [glob](https://docs.python.org/3/library/glob.html) to find the path of all parquet files in the directory `PRICE_DATA`.\n",
    "\n",
    "(1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "price_data = os.getenv(\"PRICE_DATA\")\n",
    "parquet_files = glob(os.path.join(price_data, \"**\", \"*.parquet\"), recursive=True) if price_data else []\n",
    "\n",
    "# Write your code below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ticker and using Dask, do the following:\n",
    "\n",
    "+ Add lags for variables Close and Adj_Close.\n",
    "+ Add returns based on Close:\n",
    "    \n",
    "    - `returns`: (Close / Close_lag_1) - 1\n",
    "\n",
    "+ Add the following range: \n",
    "\n",
    "    - `hi_lo_range`: this is the day's High minus Low.\n",
    "\n",
    "+ Assign the result to `dd_feat`.\n",
    "\n",
    "(4 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below.\n",
    "# Load the data\n",
    "dd_feat = dd.read_parquet(parquet_files)\n",
    "dd_feat = dd_feat.sort_values(['ticker', 'Date'])\n",
    "dd_feat['hi_lo_range'] = dd_feat['High'] - dd_feat['Low']\n",
    "dd_feat = dd_feat.set_index('ticker').persist()\n",
    "def add_lag_features(df):\n",
    "    \"\"\"Apply lag operations within each partition\"\"\"\n",
    "    df = df.sort_values('Date')\n",
    "    df['Close_lag_1'] = df['Close'].shift(1)\n",
    "    df['Adj_Close_lag_1'] = df['Adj Close'].shift(1)\n",
    "    df['returns'] = (df['Close'] / df['Close_lag_1']) - 1\n",
    "    return df\n",
    "dd_feat = dd_feat.map_partitions(add_lag_features)\n",
    "dd_feat = dd_feat.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only rolling dataframes with known divisions\nSee https://docs.dask.org/en/latest/dataframe-design.html#partitions\nfor more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdd_feat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mticker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreturns\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrolling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_p/lib/python3.9/site-packages/dask_expr/_groupby.py:2169\u001b[0m, in \u001b[0;36mGroupBy.rolling\u001b[0;34m(self, window, min_periods, center, win_type, axis)\u001b[0m\n\u001b[1;32m   2130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Provides rolling transformations.\u001b[39;00m\n\u001b[1;32m   2131\u001b[0m \n\u001b[1;32m   2132\u001b[0m \u001b[38;5;124;03m.. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2165\u001b[0m \u001b[38;5;124;03m>>> result = ddf.groupby(\"name\").x.rolling('1D').max()\u001b[39;00m\n\u001b[1;32m   2166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2167\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask_expr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rolling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Rolling\n\u001b[0;32m-> 2169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRolling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_periods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwin_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroupby_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mby\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2178\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobserved\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdropna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2180\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgroup_keys\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroupby_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dsi_p/lib/python3.9/site-packages/dask_expr/_rolling.py:256\u001b[0m, in \u001b[0;36mRolling.__init__\u001b[0;34m(self, obj, window, groupby_kwargs, groupby_slice, min_periods, center, win_type)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mdivisions[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdivisions) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    251\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only rolling dataframes with known divisions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://docs.dask.org/en/latest/dataframe-design.html#partitions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m     )\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow \u001b[38;5;241m=\u001b[39m window\n",
      "\u001b[0;31mValueError\u001b[0m: Can only rolling dataframes with known divisions\nSee https://docs.dask.org/en/latest/dataframe-design.html#partitions\nfor more information."
     ]
    }
   ],
   "source": [
    "dd_feat.groupby('ticker')['returns'].rolling(window=10, min_periods=1).mean().reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Convert the Dask data frame to a pandas data frame. \n",
    "+ Add a new feature containing the moving average of `returns` using a window of 10 days. There are several ways to solve this task, a simple one uses `.rolling(10).mean()`.\n",
    "\n",
    "(3 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>source</th>\n",
       "      <th>Year</th>\n",
       "      <th>hi_lo_range</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Adj_Close_lag_1</th>\n",
       "      <th>returns</th>\n",
       "      <th>returns_ma_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFB</td>\n",
       "      <td>2002-01-29</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.040000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.010000</td>\n",
       "      <td>5.051744</td>\n",
       "      <td>361500.0</td>\n",
       "      <td>AFB.csv</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFB</td>\n",
       "      <td>2002-01-30</td>\n",
       "      <td>15.010000</td>\n",
       "      <td>15.010000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.048384</td>\n",
       "      <td>68200.0</td>\n",
       "      <td>AFB.csv</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>15.010000</td>\n",
       "      <td>5.051744</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.000666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFB</td>\n",
       "      <td>2002-01-31</td>\n",
       "      <td>15.010000</td>\n",
       "      <td>15.010000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.048384</td>\n",
       "      <td>68800.0</td>\n",
       "      <td>AFB.csv</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.048384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFB</td>\n",
       "      <td>2002-02-01</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.010000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.048384</td>\n",
       "      <td>24900.0</td>\n",
       "      <td>AFB.csv</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.048384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFB</td>\n",
       "      <td>2002-02-04</td>\n",
       "      <td>15.050000</td>\n",
       "      <td>15.050000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.048384</td>\n",
       "      <td>75500.0</td>\n",
       "      <td>AFB.csv</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.048384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>XSW</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>80.620003</td>\n",
       "      <td>84.459999</td>\n",
       "      <td>80.620003</td>\n",
       "      <td>84.400002</td>\n",
       "      <td>84.400002</td>\n",
       "      <td>80400.0</td>\n",
       "      <td>XSW.csv</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.839996</td>\n",
       "      <td>79.839996</td>\n",
       "      <td>79.839996</td>\n",
       "      <td>0.057114</td>\n",
       "      <td>0.010889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>XSW</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>82.389999</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>80.940002</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>50900.0</td>\n",
       "      <td>XSW.csv</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.559998</td>\n",
       "      <td>84.400002</td>\n",
       "      <td>84.400002</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>0.002001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>XSW</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>81.949997</td>\n",
       "      <td>83.489998</td>\n",
       "      <td>81.949997</td>\n",
       "      <td>83.489998</td>\n",
       "      <td>83.489998</td>\n",
       "      <td>28600.0</td>\n",
       "      <td>XSW.csv</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.540001</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>0.021909</td>\n",
       "      <td>0.016743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>XSW</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>83.510002</td>\n",
       "      <td>84.190002</td>\n",
       "      <td>81.129997</td>\n",
       "      <td>82.089996</td>\n",
       "      <td>82.089996</td>\n",
       "      <td>69100.0</td>\n",
       "      <td>XSW.csv</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.060005</td>\n",
       "      <td>83.489998</td>\n",
       "      <td>83.489998</td>\n",
       "      <td>-0.016768</td>\n",
       "      <td>0.009471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>XSW</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>78.790001</td>\n",
       "      <td>80.220001</td>\n",
       "      <td>76.839996</td>\n",
       "      <td>77.459999</td>\n",
       "      <td>77.459999</td>\n",
       "      <td>31600.0</td>\n",
       "      <td>XSW.csv</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.380005</td>\n",
       "      <td>82.089996</td>\n",
       "      <td>82.089996</td>\n",
       "      <td>-0.056401</td>\n",
       "      <td>0.011090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101914 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker       Date       Open       High        Low      Close  Adj Close  \\\n",
       "0       AFB 2002-01-29  15.000000  15.040000  15.000000  15.010000   5.051744   \n",
       "1       AFB 2002-01-30  15.010000  15.010000  15.000000  15.000000   5.048384   \n",
       "2       AFB 2002-01-31  15.010000  15.010000  15.000000  15.000000   5.048384   \n",
       "3       AFB 2002-02-01  15.000000  15.010000  15.000000  15.000000   5.048384   \n",
       "4       AFB 2002-02-04  15.050000  15.050000  15.000000  15.000000   5.048384   \n",
       "...     ...        ...        ...        ...        ...        ...        ...   \n",
       "2135    XSW 2020-03-26  80.620003  84.459999  80.620003  84.400002  84.400002   \n",
       "2136    XSW 2020-03-27  82.389999  83.500000  80.940002  81.699997  81.699997   \n",
       "2137    XSW 2020-03-30  81.949997  83.489998  81.949997  83.489998  83.489998   \n",
       "2138    XSW 2020-03-31  83.510002  84.190002  81.129997  82.089996  82.089996   \n",
       "2139    XSW 2020-04-01  78.790001  80.220001  76.839996  77.459999  77.459999   \n",
       "\n",
       "        Volume   source  Year  hi_lo_range  Close_lag_1  Adj_Close_lag_1  \\\n",
       "0     361500.0  AFB.csv  2002     0.040000          NaN              NaN   \n",
       "1      68200.0  AFB.csv  2002     0.010000    15.010000         5.051744   \n",
       "2      68800.0  AFB.csv  2002     0.010000    15.000000         5.048384   \n",
       "3      24900.0  AFB.csv  2002     0.010000    15.000000         5.048384   \n",
       "4      75500.0  AFB.csv  2002     0.050000    15.000000         5.048384   \n",
       "...        ...      ...   ...          ...          ...              ...   \n",
       "2135   80400.0  XSW.csv  2020     3.839996    79.839996        79.839996   \n",
       "2136   50900.0  XSW.csv  2020     2.559998    84.400002        84.400002   \n",
       "2137   28600.0  XSW.csv  2020     1.540001    81.699997        81.699997   \n",
       "2138   69100.0  XSW.csv  2020     3.060005    83.489998        83.489998   \n",
       "2139   31600.0  XSW.csv  2020     3.380005    82.089996        82.089996   \n",
       "\n",
       "       returns  returns_ma_10  \n",
       "0          NaN            NaN  \n",
       "1    -0.000666      -0.000666  \n",
       "2     0.000000      -0.000333  \n",
       "3     0.000000      -0.000222  \n",
       "4     0.000000      -0.000167  \n",
       "...        ...            ...  \n",
       "2135  0.057114       0.010889  \n",
       "2136 -0.031991       0.002001  \n",
       "2137  0.021909       0.016743  \n",
       "2138 -0.016768       0.009471  \n",
       "2139 -0.056401       0.011090  \n",
       "\n",
       "[101914 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code below.\n",
    "# Convert Dask DataFrame to pandas DataFrame\n",
    "df_feat = dd_feat.compute()\n",
    "df_feat['returns_ma_10'] = df_feat.groupby('ticker')['returns'].rolling(window=10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "df_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please comment:\n",
    "\n",
    "+ Was it necessary to convert to pandas to calculate the moving average return?\n",
    "+ Would it have been better to do it in Dask? Why?\n",
    "\n",
    "**Comments:**\n",
    "\n",
    "**Was it necessary to convert to pandas?**\n",
    "Yes, it was necessary in this case. As demonstrated by the error encountered earlier, Dask's rolling operations require \"known divisions\" - meaning Dask needs to know exactly where each partition begins and ends. When we use `map_partitions` to add lag features, the resulting DataFrame loses its known divisions because the partitioning structure becomes uncertain. This makes rolling operations impossible in Dask without additional steps to repartition and sort the data properly.\n",
    "\n",
    "**Would it have been better to do it in Dask?**\n",
    "In theory, yes - it would be better to stay in Dask for several reasons:\n",
    "- **Memory efficiency**: Dask can handle datasets larger than RAM by processing partitions sequentially\n",
    "- **Scalability**: For very large datasets, converting to pandas could cause memory issues\n",
    "- **Consistency**: Keeping everything in the same framework reduces data transfer overhead\n",
    "\n",
    "However, in practice, implementing rolling operations with grouped data in Dask is more complex and would require:\n",
    "- Proper repartitioning by ticker to ensure each ticker's data is contiguous\n",
    "- Setting known divisions after repartitioning\n",
    "- More complex code to handle edge cases at partition boundaries\n",
    "\n",
    "For this dataset size, converting to pandas was the most practical solution, but for production systems with much larger datasets, the additional complexity of staying in Dask would be worthwhile.\n",
    "\n",
    "(1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria\n",
    "\n",
    "The [rubric](./assignment_1_rubric_clean.xlsx) contains the criteria for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-1`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
