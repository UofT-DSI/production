{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv \n",
    "%run update_path.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "ft_path = os.getenv(\"CREDIT_DATA\")\n",
    "df_raw = pd.read_csv(ft_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from credit.data import load_data\n",
    "\n",
    "X, Y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model Artifacts\n",
    "\n",
    "Previously, we built a procedure for hyperparameter tuning. The process produces parametrized models that use the optimal parameters based on Grid Search or Hyperopt. The models are saved in the object store. We can access these objects via MLFlow's API using the uri: `models:/<model name>/<model version>`\n",
    "\n",
    "Alternatively, the model could have been stored using the standard pickle format. We can load a model using `pickle.load()` within  a context manager that handles the file (a `with(open(f, 'rb'))...` statement). The context manager will help close files in case of unexpected termination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow.sklearn\n",
    "# mlflow.set_tracking_uri('http://localhost:5001')\n",
    "# model_name = 'CreditLogisticModel'\n",
    "# model_version = '6'\n",
    "# model_uri = f'models:/{model_name}/{model_version}'\n",
    "# pipe = mlflow.sklearn.load_model(model_uri)\n",
    "# pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./models/credit_logistic_grid_search.pkl', 'rb') as f:\n",
    "    pipe = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we loaded a logistic regression model. The model, however, could have been from another family of models (Random Forest, Neural Net, etc.)\n",
    "\n",
    "Below, we will explore some model-agnostic explainability methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Dependence Plots\n",
    "\n",
    "+ [Partial Dependence Plots (PDP)](https://scikit-learn.org/stable/modules/partial_dependence.html) show the relationship between the target response and the input feature. \n",
    "+ They can be constructed for one or two inputs at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Why do we fit again?\n",
    "\n",
    "pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Feature PDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PartialDependenceDisplay.from_estimator(pipe, X_train, \n",
    "                                        features = ['revolving_unsecured_line_utilization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PartialDependenceDisplay.from_estimator(pipe, X_train, \n",
    "                                        features = ['revolving_unsecured_line_utilization', 'debt_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Feature PDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PartialDependenceDisplay.from_estimator(pipe, X_train, \n",
    "                                        features = [('revolving_unsecured_line_utilization', 'debt_ratio')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependence Values\n",
    "\n",
    "You may require the underlying data of the plots above. To obtain it, use the function [`partial_dependence()`](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.partial_dependence.html#sklearn.inspection.partial_dependence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "partial_dependence(pipe, X_train, features = ['revolving_unsecured_line_utilization', 'high_debt_ratio'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Feature Importance\n",
    "\n",
    "+ Permutation feature importance measures the contribution of each feature to a fitted model's performance.\n",
    "+ Randomly shuffles the values of a single feature and observing the result degradation of the model's score. If shuffling a feature greatly degrades performance, then we say the feature is important.\n",
    "+ Shuffling is involved, therefore it is convenient (and costly) to perform several repetitions.\n",
    "\n",
    "[Scikit's Documentation](https://scikit-learn.org/stable/modules/permutation_importance.html) makes this warning:\n",
    "\n",
    "> **Warning**: Features that are deemed of **low importance for a bad model** (low cross-validation score) could be **very important for a good model**. Therefore it is always important to evaluate the predictive power of a model using a held-out set (or better with cross-validation) prior to computing importances. Permutation importance does not reflect to the intrinsic predictive value of a feature by itself but how important this feature is for a particular model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "pi_res = permutation_importance(\n",
    "    pipe, X_test, y_test, \n",
    "    n_repeats=30, \n",
    "    scoring = \"neg_log_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns a dictionary with the following entries:\n",
    "\n",
    "+ `importances_mean`: mean of feature importance.\n",
    "+ `importances_std`: standard deviation of feature importance over n_repeats.\n",
    "+ `importances`: raw permutation importance scores (one feature per row, one reshuffle per column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_dt = pd.DataFrame(pi_res.importances).T\n",
    "importances_dt.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "bp = plt.boxplot(importances_dt, vert = False,  labels = importances_dt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        pd.Series(pi_res.importances_mean, index = X_test.columns, name = 'Mean Importance'),\n",
    "        pd.Series(pi_res.importances_std, index = X_test.columns, name = \"Std Importance\")\n",
    "    ], \n",
    "    axis = 1).sort_values(\"Mean Importance\", ascending  = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Values\n",
    "\n",
    "\n",
    "+ SHAP is an advanced approach for providing explanation to model results. \n",
    "+ One library that implements this procedure is [Shap](https://shap.readthedocs.io/en/latest/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainers\n",
    "\n",
    "+ SHAP values can be calculated for any model, however, the procedure can be computationally expensive.\n",
    "+ For certain models, some specific functions exist to speed the cauclations: they are contained in the [`shap.explainers`](https://shap.readthedocs.io/en/latest/api.html#explainers) module. A few noteable functions are:\n",
    "\n",
    "    - [`shap.Explainer()`](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer): the primary explainer interface and chooses the explanation algorithm for you.\n",
    "    - [`shap.TreeExplainer()`](https://shap.readthedocs.io/en/latest/generated/shap.TreeExplainer.html#shap.TreeExplainer): implements Tree Shap, a procedure optimized for tree-based ensemble methods (Random Forest, XGBoost, etc.)\n",
    "    - [`shap.LinearExplainer()`](https://shap.readthedocs.io/en/latest/generated/shap.LinearExplainer.html#shap.LinearExplainer): computes SHAP Values for linear methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining explanations from shap\n",
    "\n",
    "+ Shap can obtain local and global explanations. The model produces additive explanations, therefore, obtaining global explanations is equivalent to obtaining individual explanations for all samples.\n",
    "+ Shap can obtain explanations for testing and training samples.\n",
    "+ Local explanations are obtained as shap_values, which reflect the contribution of each feature to the prediction made for each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the shap package\n",
    "\n",
    "+ SHAP works on classifiers, but our pipelines contain preprocessing and classification steps. \n",
    "+ We can access each individual step through the `.named_steps` attirbute.\n",
    "+ Notice that we apply the transformation (`ColumnTransformer`) step to obtain transformed data and store the results in `data_transform`.\n",
    "+ Feature names are obtained from the preprocessor's `.get_feature_names_out()` which exposes the names of the features after they have been transformed by the `ColumnTransformer`.\n",
    "+ The explainer object is then use to provide all explanations in `data_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "data_transform = pipe.named_steps['preproc'].transform(X_test)\n",
    "\n",
    "explainer = shap.explainers.Linear(\n",
    "    pipe.named_steps['clf'], \n",
    "    data_transform,\n",
    "    feature_names = pipe.named_steps['preproc'].get_feature_names_out())\n",
    "\n",
    "shap_values = explainer(data_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waterfall Plots\n",
    "\n",
    "From [SHAP's documentation](https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/waterfall.html) (emphasis added):\n",
    "\n",
    "\n",
    "> Waterfall plots are designed to display explanations for **individual predictions**, so they expect a single row of an Explanation object as input. The bottom of a waterfall plot starts as the expected value of the model output, and then each row shows how the positive (red) or negative (blue) contribution of each feature moves the value from the expected model output over the background dataset to the model output for this prediction.\n",
    "\n",
    "+ The waterfall plot below shows the contribution of each feature to an individual prediction. \n",
    "+ Only the most important features are shown, while the least important features are grouped together at the bottom of the chart (e.g., \"4 other features\").\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beeswarm plot\n",
    "\n",
    "+ Beeswarm plots display the contributions of each feature to all cases in the sample. The feature values are color-coded when available. \n",
    "+ Beeswarm plots summarize the behaviour of the model across all items in the sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "production-env (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
