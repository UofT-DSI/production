{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we doing?\n",
    "\n",
    "## Objectives\n",
    "\n",
    "+ Construct a cross-validation pipeline.\n",
    "+ Use cross-validation to evaluate different hyperparameter performance.\n",
    "+ Perform grid search for systemic evaluation.\n",
    "+ Store and manage results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "\n",
    "The diagram below, taken from Scikit Learn's documentation, shows the procedure that we will follow:\n",
    "\n",
    "<div>\n",
    "<img src=\"./images/05_grid_search_workflow.png\" height=\"500\"/>\n",
    "</div>\n",
    "\n",
    "+ System requirements:\n",
    "    \n",
    "    - Automation: the system should operate automatically with the least amount of supervision. \n",
    "    - Replicability: changes to code and (arguably) data should be logged and controlled. Randomness should also be controlled (e.g., random seeds).\n",
    "    - Persistence: persist results for later analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Hyperparameter?\n",
    "\n",
    "+ Generally speaking, hyperparameters are parameters that control the learning process: regularization weights, learning rate, entropy/gini metrics, etc. \n",
    "+ Hyperparameters determine a model's behaviour and performance. Model selection is intimately related to hyperparameter tuning. \n",
    "+ Selection criteria are based on performance evaluation. To get better performance estimates, we use cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching the Hyperparameter Grid\n",
    "\n",
    "+ To address the automation requirement, we could use `GridSearchCV()`, which is a self-contained function for performing a Grid Search over a hyperparameter space.\n",
    "+ To \"Search the Hyperparameter Grid\" exhaustively means that we will consider all possible combinations of hyperparameter values in the search space and evaluate the model using those hyperparameters. For example, if we have two parameters that we are exploring, kernel (takes values \"rbf\" and \"poly\") and C (takes values 1.0 and 0.5), then this grid would be the combinations:\n",
    "\n",
    "    + (rbf, 1.0)\n",
    "    + (rbf, 0.5)\n",
    "    + (poly, 1.0)\n",
    "    + (poly, 0.5)\n",
    "\n",
    "+ Under each combination, we perform CV and evaluate the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "We start with [Give me some credit](https://www.kaggle.com/c/GiveMeSomeCredit) data that we used in the previous session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv \n",
    "%run update_path.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "ft_path = os.getenv(\"CREDIT_DATA\")\n",
    "df_raw = pd.read_csv(ft_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.drop(columns = [\"Unnamed: 0\"]).rename(\n",
    "    columns = {\n",
    "        'SeriousDlqin2yrs': 'delinquency',\n",
    "        'RevolvingUtilizationOfUnsecuredLines': 'revolving_unsecured_line_utilization', \n",
    "        'age': 'age',\n",
    "        'NumberOfTime30-59DaysPastDueNotWorse': 'num_30_59_days_late', \n",
    "        'DebtRatio': 'debt_ratio', \n",
    "        'MonthlyIncome': 'monthly_income',\n",
    "        'NumberOfOpenCreditLinesAndLoans': 'num_open_credit_loans', \n",
    "        'NumberOfTimes90DaysLate':  'num_90_days_late',\n",
    "        'NumberRealEstateLoansOrLines': 'num_real_estate_loans', \n",
    "        'NumberOfTime60-89DaysPastDueNotWorse': 'num_60_89_days_late',\n",
    "        'NumberOfDependents': 'num_dependents'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a simple pipeline composed of:\n",
    "\n",
    "+ Preprocessing steps.\n",
    "+ Logistic Regression classifier.\n",
    "\n",
    "We will explore the hyperparameter space by evaluating different regularization strategies and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = ['revolving_unsecured_line_utilization', 'age',\n",
    "       'num_30_59_days_late', 'debt_ratio', 'monthly_income',\n",
    "       'num_open_credit_loans', 'num_90_days_late', 'num_real_estate_loans',\n",
    "       'num_60_89_days_late', 'num_dependents'\n",
    "       ]\n",
    "\n",
    "pipe_num_simple = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "    ('standardizer', StandardScaler())\n",
    "])\n",
    "\n",
    "ctransform_simple= ColumnTransformer([\n",
    "    ('numeric_simple', pipe_num_simple, num_cols),\n",
    "], remainder='passthrough')\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    ('preprocess', ctransform_simple),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "pipe_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the parameters of the pipeline with `.get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Splitting Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'delinquency')\n",
    "Y = df['delinquency']\n",
    "\n",
    "scoring = ['neg_log_loss', 'roc_auc', 'f1', 'accuracy', 'precision', 'recall']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the Grid Search, we need to define a parameter grid:\n",
    "\n",
    "- A parameter grid defines all of the combinations of parameters that we need to explore.\n",
    "- The function `GridSearchCV()` performs an exhaustive search of parameter combinations.\n",
    "- The parameter grid is defined as a dictionary of lists:\n",
    "\n",
    "    * Each entry's key is the name of the parameter.\n",
    "    * Each entry's value is the list of values that we would like to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__solver': ['liblinear'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some key inputs to [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) are:\n",
    "\n",
    "+ `estimator`: the pipeline or classifier that we are tuning.\n",
    "+ `param_grid`: the parameter grid defined as a dictionary of lists described above.\n",
    "+ `n_jobs`: settings for parallel computation.\n",
    "+ `refit`: options for refitting the model using the best-performing configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(\n",
    "    estimator=pipe_lr, \n",
    "    param_grid=param_grid, \n",
    "    scoring = scoring, \n",
    "    cv = 5,\n",
    "    refit = \"neg_log_loss\")\n",
    "grid_cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the cross-validation results using the property `.cv_results_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = grid_cv.cv_results_\n",
    "res = pd.DataFrame(res)\n",
    "res.columns\n",
    "\n",
    "res[['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
    "       'param_clf__C', 'param_clf__penalty', 'param_clf__solver', 'params',\n",
    "       'mean_test_neg_log_loss',\n",
    "       'std_test_neg_log_loss', 'rank_test_neg_log_loss']].sort_values('rank_test_neg_log_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the best-performing configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best-performing classifier (pipeline) trained on the complete training set is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model artifact\n",
    "\n",
    "We use `pickle`, a binary file format, to store the best-performing model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "with open('./models/credit_logistic_grid_search.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_cv.best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking GridSearchCV Experiments\n",
    "\n",
    "+ We can expand our infrastructure for hyperparameter tuning across various models.\n",
    "+ The plan:\n",
    "\n",
    "    - Create a model ingredient to obtain the classifier object.\n",
    "    - Create experiment parameter grids to organize our parameter grids.\n",
    "    - Schedule the experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the code in `./05_src/exp__logistic_simple.py` and `./05_src/exp__logistic_grid_search.py`:\n",
    "\n",
    "+ `exp__logistic_simple.py` runs a single experiment in MLFlow; i.e., a single set of parameters is trained and evaluated by the code.\n",
    "+ `exp__logistic_grid_search.py` runs through a series of tests (one test given by a parametrization of the model pipeline). Each run is recorded independently as a parent run.\n",
    "+ Also, notice that we have pulled the data component of the experiment to a module of its own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Experiments from the Command Line\n",
    "\n",
    "Access the experiment through the [Command Line Interface](https://sacred.readthedocs.io/en/stable/command_line.html).\n",
    "\n",
    "```\n",
    "cd src  # if required\n",
    "python -m credit.exp__logistic_grid_search.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "production-env (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
